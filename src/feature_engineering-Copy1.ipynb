{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_train_data = pd.read_csv(\"data/train_2008.csv\")\n",
    "train_data = orig_data.copy()\n",
    "\n",
    "orig_test_data = pd.read_csv(\"data/test_2008.csv\")\n",
    "test_data = orig_test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_orig_cols = list(orig_train_data.columns) # original columns, with target PES1 on the end\n",
    "target_var = orig_train_data['PES1']\n",
    "target_var_bin = target_var.apply(lambda x: 0 if x == 2 else x)\n",
    "train_data.drop('PES1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect all features that are bad and need to be dropped\n",
    "allocation_flag_feats = ['PRCITFLG', 'PRWERNAL', 'PRHERNAL', 'HXTENURE', 'HXHOUSUT', \n",
    "                         'HXTELHHD', 'HXTELAVL', 'HXPHONEO']\n",
    "allocation_flag_feats.extend([col for col in train_data.columns if col[:2] == 'PX'])\n",
    "\n",
    "recode_feats = [\"PRFAMNUM\",\"PRFAMREL\",\"PRFAMTYP\",\"PRPERTYP\",\"PEMLR\",\"PRDISC\",\n",
    "                \"PRJOBSEA\",\"PRWNTJOB\",\"PRCOW1\",\"PRCOW2\",\"PRDTCOW1\",\"PRDTCOW2\",\"PRDTIND1\",\n",
    "                \"PRDTIND2\",\"PRDTOCC1\",\"PRDTOCC2\",\"PREMP\",\"PRMJIND1\",\"PRMJIND2\",\"PRMJOCC1\",\n",
    "                \"PRMJOCC2\",\"PRNAGPWS\",\"PRNAGWS\",\"PRERNHLY\",\"PRERNWA\",\n",
    "                \"PRIMIND1\",\"PRIMIND2\",\"PRTFAGE\",\"PTHR\",\"PTWK\",\"PTOT\",]\n",
    "\n",
    "one_answer_feats = ['HRMONTH', 'HRYEAR4', 'HUBUSL3', 'HUBUSL4', 'PULAYAVR', 'PULKDK2', \n",
    "                    'PULKDK3', 'PULKDK4', 'PULKDK5', 'PULKDK6', 'PULKPS2', 'PULKPS3', \n",
    "                    'PULKPS4', 'PULKPS5', 'PULKPS6', 'PUDWCK3', 'PUJHDP1O', 'PUERNH1C', \n",
    "                    'PTHR', 'PUERN2', 'PTOT',]\n",
    "for feat in train_data.columns:\n",
    "    if len(train_data[feat].unique()) == 1:\n",
    "        one_answer_feats.append(feat)\n",
    "        \n",
    "bad_feats = ['QSTNUM', 'PRERNWA', 'PRERNHLY', 'PEERNH1O', 'HRHHID2', 'GTCSA', 'GTCO', \n",
    "             'HUINTTYP', 'HURESPLI', 'HRMIS', 'PRDTOCC1', 'PRFAMREL', 'PUSLFPRX', 'OCCURNUM',\n",
    "             'PULINENO', 'PRMJOCC1', 'PRCHLD', 'GTCBSA', 'HRLONGLK', 'HUTYPB']\n",
    "\n",
    "weight_feats = [col for col in train_data.columns if col[-3:] == 'WGT']\n",
    "\n",
    "# Put them all together, and remove duplicates\n",
    "feats_to_drop = list(set(allocation_flag_feats + recode_feats + one_answer_feats + \n",
    "                         bad_feats + weight_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the bad columns\n",
    "train_data.drop(feats_to_drop, axis=1, inplace=True)\n",
    "test_data.drop(feats_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummify categorical vars\n",
    "to_dummy = ['GEREG', 'HUBUS', 'PTDTRACE', 'PENATVTY', 'PUABSOT', 'PEIO1COW', 'HUFINAL', 'GESTCEN', 'GESTFIPS',\n",
    "            'PEIO1ICD', 'PEIO1OCD', 'PEIO2ICD', 'PEIO2OCD', 'PRCITSHP', 'PUDIS', \n",
    "           'PRABSREA', 'PRWKSTAT', 'HUPRSCNT', 'PERRP', 'GTCBSAST', 'PRMJOCGR', 'HRHTYPE', ]\n",
    "\n",
    "train_dummy_df = pd.DataFrame()\n",
    "test_dummy_df = pd.DataFrame()\n",
    "\n",
    "for var in to_dummy:\n",
    "    train_dummy_vars = pd.get_dummies(train_data[var], prefix=var)\n",
    "    train_dummy_df = pd.concat([train_dummy_df, train_dummy_vars], axis=1)\n",
    "    \n",
    "    test_dummy_vars = pd.get_dummies(test_data[var], prefix=var)\n",
    "    test_dummy_df = pd.concat([test_dummy_df, test_dummy_vars], axis=1)\n",
    "    \n",
    "# Drop the original categorical variables\n",
    "train_data.drop(to_dummy, axis=1, inplace=True)\n",
    "test_data.drop(to_dummy, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add dummy vars to the data\n",
    "train_data = pd.concat([train_data, train_dummy_df], axis=1)\n",
    "test_data = pd.concat([test_data, test_dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of non-dummy variables\n",
    "non_dummy_cols = [col for col in train_data.columns if '_' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### First pass - use mean for NaN. Later we'll do intelligent filling on important features\n",
    "\n",
    "# Replace negative values (all forms of N/A) with NaN\n",
    "for feat in train_data.columns:\n",
    "    train_data[feat] = train_data[feat].apply(lambda x: np.NaN if x < 0 else x)\n",
    "    try:\n",
    "        test_data[feat] = test_data[feat].apply(lambda x: np.NaN if x < 0 else x)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "# Replace NaN with the mean of the column\n",
    "for feat in train_data.columns:\n",
    "    train_data[feat].fillna(train_data[feat].mean(), inplace=True)\n",
    "    try:\n",
    "        test_data[feat].fillna(test_data[feat].mean(), inplace=True)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "# Check for columns that are all NaN, and delete them\n",
    "nan_cols = []\n",
    "for feat in train_data.columns:\n",
    "    if np.all(np.isnan(train_data[feat])):\n",
    "        nan_cols.append(feat)\n",
    "train_data.drop(nan_cols, axis=1, inplace=True)\n",
    "test_data.drop(nan_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update non-dummy variables\n",
    "non_dummy_cols = [col for col in train_data.columns if '_' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Few more cleanups\n",
    "train_data.drop('id', axis=1, inplace=True)\n",
    "test_data.drop('id', axis=1, inplace=True)\n",
    "train_data['PES1'] = target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats_test_needs = [f for f in train_data.columns if f not in test_data.columns and f != 'PES1']\n",
    "feats_test_drop = [f for f in test_data.columns if f not in train_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat in feats_test_needs:\n",
    "    test_data[feat] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.drop(feats_train_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns) == len(test_data.columns) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1625"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.drop(feats_test_needs, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure columns are in same order\n",
    "test_data = test_data[train_data.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A couple checks first\n",
    "assert train_data.columns[-1] == 'PES1'\n",
    "assert len(train_data.columns) == len(test_data.columns) + 1\n",
    "assert (train_data.columns[:-1] == test_data.columns).all()\n",
    "assert train_data.isnull().values.any() == False\n",
    "assert test_data.isnull().values.any() == False\n",
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rewrite out the non-feature-selected data sets\n",
    "train_data.to_csv(\"data/training_data_feat_eng_mean_fill_raw.csv\", index=False)\n",
    "test_data.to_csv(\"data/test_data_feat_eng_mean_fill_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# null_cols = []\n",
    "# for feat in train_data.columns:\n",
    "#     if pd.isnull(train_data[feat]).values.any():\n",
    "#         null_cols.append(feat)\n",
    "# for feat in test_data.columns:\n",
    "#     if pd.isnull(test_data[feat]).values.any():\n",
    "#         null_cols.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUBUSCK1\n",
      "PUDIS2\n",
      "PULKDK1\n",
      "PUNLFCK2\n"
     ]
    }
   ],
   "source": [
    "# for col in null_cols:\n",
    "#     print(col)\n",
    "#     train_data[col].fillna(get_fill_value(train_data[col]), inplace=True)\n",
    "#     test_data[col].fillna(get_fill_value(test_data[col]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a classifier for evaluating most important features\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier(n_estimators=200)\n",
    "clf = clf.fit(train_data.ix[:, :-1], target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dataframe of the features and their importances\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = train_data.columns[:-1]\n",
    "features['importance'] = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PEEDUCA</td>\n",
       "      <td>0.029726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PEAGE</td>\n",
       "      <td>0.023882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HUFAMINC</td>\n",
       "      <td>0.022802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HETENURE</td>\n",
       "      <td>0.013730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GTCBSASZ</td>\n",
       "      <td>0.013288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HRNUMHOU</td>\n",
       "      <td>0.013167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>PECYC</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PEMARITL</td>\n",
       "      <td>0.009870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRMARSTA</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>PRNMCHLD</td>\n",
       "      <td>0.008654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PESEX</td>\n",
       "      <td>0.008312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>GTCBSAST_2</td>\n",
       "      <td>0.007952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>HUPRSCNT_0</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>PRMJOCGR_1</td>\n",
       "      <td>0.007617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>PEGRPROF</td>\n",
       "      <td>0.007325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>HUPRSCNT_1</td>\n",
       "      <td>0.007266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>PRDTIND1</td>\n",
       "      <td>0.006736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>GTCBSAST_1</td>\n",
       "      <td>0.006462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>GTCBSAST_4</td>\n",
       "      <td>0.006455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>GEREG_3</td>\n",
       "      <td>0.006399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>PRIMIND1</td>\n",
       "      <td>0.006361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEHOUSUT</td>\n",
       "      <td>0.006279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>PERRP_1</td>\n",
       "      <td>0.006279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>PESCHENR</td>\n",
       "      <td>0.006223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>PRMJIND1</td>\n",
       "      <td>0.006217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PEFNTVTY</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PEHRACT1</td>\n",
       "      <td>0.005901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PEHRACTT</td>\n",
       "      <td>0.005891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>GEREG_2</td>\n",
       "      <td>0.005866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>GTCBSAST_3</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>GESTCEN_11</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>GESTFIPS_54</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>GESTFIPS_8</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>GESTFIPS_15</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>HUPRSCNT_3</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>GESTCEN_47</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>GESTFIPS_20</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>GESTCEN_95</td>\n",
       "      <td>0.001533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>GESTCEN_22</td>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PUBUSCK3</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>GESTCEN_84</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>GESTCEN_54</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>GESTCEN_62</td>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>GESTFIPS_51</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>GESTFIPS_34</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>GESTFIPS_23</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>GESTCEN_35</td>\n",
       "      <td>0.001498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>GESTFIPS_27</td>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>GESTFIPS_47</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>GESTFIPS_55</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>GESTCEN_41</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>GESTFIPS_44</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PUHRCK4</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>GESTCEN_43</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>GESTCEN_57</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PEHRRSN2</td>\n",
       "      <td>0.001470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>GESTFIPS_45</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>PRWKSTAT_4</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>GESTFIPS_29</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>GESTCEN_61</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "20        PEEDUCA    0.029726\n",
       "14          PEAGE    0.023882\n",
       "6        HUFAMINC    0.022802\n",
       "1        HETENURE    0.013730\n",
       "12       GTCBSASZ    0.013288\n",
       "7        HRNUMHOU    0.013167\n",
       "180         PECYC    0.011053\n",
       "16       PEMARITL    0.009870\n",
       "26       PRMARSTA    0.009623\n",
       "177      PRNMCHLD    0.008654\n",
       "18          PESEX    0.008312\n",
       "1627   GTCBSAST_2    0.007952\n",
       "1599   HUPRSCNT_0    0.007788\n",
       "1631   PRMJOCGR_1    0.007617\n",
       "181      PEGRPROF    0.007325\n",
       "1600   HUPRSCNT_1    0.007266\n",
       "146      PRDTIND1    0.006736\n",
       "1626   GTCBSAST_1    0.006462\n",
       "1629   GTCBSAST_4    0.006455\n",
       "204       GEREG_3    0.006399\n",
       "184      PRIMIND1    0.006361\n",
       "2        HEHOUSUT    0.006279\n",
       "1609      PERRP_1    0.006279\n",
       "173      PESCHENR    0.006223\n",
       "150      PRMJIND1    0.006217\n",
       "28       PEFNTVTY    0.005999\n",
       "59       PEHRACT1    0.005901\n",
       "61       PEHRACTT    0.005891\n",
       "203       GEREG_2    0.005866\n",
       "1628   GTCBSAST_3    0.005736\n",
       "...           ...         ...\n",
       "395    GESTCEN_11    0.001544\n",
       "494   GESTFIPS_54    0.001544\n",
       "451    GESTFIPS_8    0.001540\n",
       "457   GESTFIPS_15    0.001538\n",
       "1602   HUPRSCNT_3    0.001538\n",
       "415    GESTCEN_47    0.001537\n",
       "462   GESTFIPS_20    0.001535\n",
       "445    GESTCEN_95    0.001533\n",
       "402    GESTCEN_22    0.001529\n",
       "36       PUBUSCK3    0.001525\n",
       "436    GESTCEN_84    0.001525\n",
       "419    GESTCEN_54    0.001514\n",
       "426    GESTCEN_62    0.001511\n",
       "492   GESTFIPS_51    0.001504\n",
       "476   GESTFIPS_34    0.001501\n",
       "465   GESTFIPS_23    0.001501\n",
       "408    GESTCEN_35    0.001498\n",
       "469   GESTFIPS_27    0.001489\n",
       "488   GESTFIPS_47    0.001488\n",
       "495   GESTFIPS_55    0.001486\n",
       "409    GESTCEN_41    0.001486\n",
       "485   GESTFIPS_44    0.001485\n",
       "66        PUHRCK4    0.001478\n",
       "411    GESTCEN_43    0.001475\n",
       "422    GESTCEN_57    0.001474\n",
       "53       PEHRRSN2    0.001470\n",
       "486   GESTFIPS_45    0.001463\n",
       "1590   PRWKSTAT_4    0.001457\n",
       "471   GESTFIPS_29    0.001455\n",
       "425    GESTCEN_61    0.001452\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the most important features\n",
    "features.sort(['importance'],ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out the most important features\n",
    "model = SelectFromModel(clf, prefit=True, threshold='1.0*mean')\n",
    "train_data_selected_feats = model.transform(train_data.ix[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64667, 336)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_selected_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kinda hacky, but we need some way of getting just the selected features in the test set (selecting features kills\n",
    "# the column names).\n",
    "imp_mean = features.importance.mean()\n",
    "keep_feats = []\n",
    "for f in features['feature']:\n",
    "    if float(features[features['feature'] == f]['importance']) >= 1.0 * imp_mean:\n",
    "        keep_feats.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keep_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keep hacking....\n",
    "keep_feats = [f for f in keep_feats if f in test_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Finally get the features we need\n",
    "train_data_selected_feats = train_data[keep_feats]\n",
    "test_data_selected_feats = test_data[keep_feats]\n",
    "\n",
    "# Add the target back to the training data\n",
    "train_data_selected_feats['targ'] = target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out the data sets\n",
    "train_data_selected_feats.to_csv(\"data/training_data_feat_eng_smart_fill_selected_feats.csv\", index=False)\n",
    "test_data_selected_feats.to_csv(\"data/test_data_feat_eng_smart_fill_selected_feats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######### Havent used this stuff yet\n",
    "\n",
    "# For numerics, define a find_min_entropy_split() function, and use that on\n",
    "# negative valued responses. Negative valued responses indicate that the\n",
    "# survey participant did not respond in some capacity.\n",
    "def get_split_points(col):\n",
    "    '''Get the points between the unique values in col. col is a pandas series. Set the stride such that\n",
    "    there are ~10 splits in the feature.'''\n",
    "    unique = col.unique()\n",
    "    sort = sorted(unique)\n",
    "    sort = [x for x in sort if not pd.isnull(x)]\n",
    "    splits = []\n",
    "    stride = int(np.ceil(len(sort) / 10))\n",
    "    i = 0\n",
    "    while i < (len(sort) - stride):\n",
    "        splits.append(0.5 * (sort[i] + sort[i + stride]))\n",
    "        i += stride\n",
    "    return splits\n",
    "\n",
    "def get_entropy(arr):\n",
    "    '''Get the entropy of an array. Assumes the values of the array are 0/1'''\n",
    "    if len(arr) == 0:\n",
    "        return 0.0\n",
    "    frac_pos = sum(arr) / len(arr)\n",
    "    size = len(arr)\n",
    "    if frac_pos == 0 or frac_pos == 1: # Workaround for defining 0 * log(0) = 0\n",
    "        return 0.0\n",
    "    return -size * (frac_pos * np.log(frac_pos) + (1 - frac_pos) * np.log(1 - frac_pos))\n",
    "\n",
    "def find_min_entropy_split(col):\n",
    "    '''Find the threshold in a column of data that a decision tree would choose using\n",
    "    the entropy impurity measure. Return that threshold, and flag indicating which side of\n",
    "    the split has higher entropy. flag=1 => the datapoints above the split have higher entropy, and\n",
    "    flag=-1 => the datapoints below the split have higher entropy.'''\n",
    "    split_points = get_split_points(col)\n",
    "    min_entropy = np.inf\n",
    "    min_entropy_split = None\n",
    "    flag = 0\n",
    "    for split in split_points:\n",
    "        bools = col > split\n",
    "        above = [i for i in range(len(col)) if bools[i]]\n",
    "        below = [i for i in range(len(col)) if not bools[i]]\n",
    "        voter_status_above = [target_var_bin[i] for i in above]\n",
    "        voter_status_below = [target_var_bin[i] for i in below]\n",
    "        entropy_above = get_entropy(voter_status_above)\n",
    "        entropy_below = get_entropy(voter_status_below)\n",
    "        entropy_total = entropy_above + entropy_below\n",
    "        if entropy_total < min_entropy:\n",
    "            min_entropy = entropy_total\n",
    "            min_entropy_split = split\n",
    "            if entropy_above > entropy_below:\n",
    "                flag = 1\n",
    "            else:\n",
    "                flag = -1\n",
    "    return min_entropy_split, flag\n",
    "\n",
    "def get_fill_value(col):\n",
    "    '''First find the split that minimizes entropy (ie the split chosen by a tree), then return the mean\n",
    "    of the half of the split that has higher entropy.'''\n",
    "    split, flag = find_min_entropy_split(col)\n",
    "    if flag == 0:\n",
    "        return 0 # This is only happening for weird cases where there's one non-null value in the whole column\n",
    "        #print(col)\n",
    "        #raise ValueError# If the flag is zero, something went wrong\n",
    "    if flag == 1:\n",
    "        higher_entropy_side = col[col > split]\n",
    "    else:\n",
    "        higher_entropy_side = col[col <= split]\n",
    "    return np.mean(higher_entropy_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
