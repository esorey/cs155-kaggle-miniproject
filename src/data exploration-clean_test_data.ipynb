{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(\"data/test_2012.csv\")\n",
    "data = orig_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_orig_cols = list(orig_data.columns) # original columns, with target PES1 on the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Goal: segment intuitively important features; standardize yes/no questions to binary\n",
    "\n",
    "# Segment HUFAMINC (family income)\n",
    "data['low_fam_inc'] = data.HUFAMINC.apply(lambda x: x >= 1 and x <= 11).astype(int)\n",
    "data['med_fam_inc'] = data.HUFAMINC.apply(lambda x: x >= 12 and x <= 14).astype(int)\n",
    "data['high_fam_inc'] = data.HUFAMINC.apply(lambda x: x >= 15).astype(int)\n",
    "\n",
    "# Segment HRNUMHOU (number of household members)\n",
    "data['one_person_hh'] = (data.HRNUMHOU == 1).astype(int)\n",
    "data['two_person_hh'] = (data.HRNUMHOU == 2).astype(int)\n",
    "data['multi_person_hh'] = (data.HRNUMHOU > 2).astype(int)\n",
    "\n",
    "# Segment HUBUS (business/farm owner?)\n",
    "data['farm_bus_hh'] = (data.HUBUS == 1).astype(int)\n",
    "data['non_farm_bus_hh'] = (data.HUBUS == 2).astype(int)\n",
    "\n",
    "# Segment GEREG (region)\n",
    "data['northeast'] = (data.GEREG == 1).astype(int)\n",
    "data['midwest'] = (data.GEREG == 2).astype(int)\n",
    "data['south'] = (data.GEREG == 3).astype(int)\n",
    "data['west'] = (data.GEREG == 4).astype(int)\n",
    "\n",
    "# Segment PEAGE (age)\n",
    "data['too_young'] = data.PEAGE.apply(lambda x: x >= 0 and x < 18).astype(int)\n",
    "data['youth'] = data.PEAGE.apply(lambda x: x >= 18 and x < 40).astype(int)\n",
    "data['middle_age'] = data.PEAGE.apply(lambda x: x >= 40 and x < 65).astype(int)\n",
    "data['elderly'] = data.PEAGE.apply(lambda x: x >= 65).astype(int)\n",
    "\n",
    "# Segment PEEDUCA (highest level of school completed or degree received)\n",
    "data['hs_dropout'] = data.PEEDUCA.apply(lambda x: x < 39).astype(int)\n",
    "data['hs_grad'] = data.PEEDUCA.apply(lambda x: x >= 39).astype(int)\n",
    "data['bachelor_deg'] = data.PEEDUCA.apply(lambda x: x >= 43).astype(int)\n",
    "data['adv_deg'] = data.PEEDUCA.apply(lambda x: x >= 44).astype(int)\n",
    "\n",
    "# Segment PTDTRACE (race)\n",
    "data['white_race'] = data.PTDTRACE.apply(lambda x: x == 1).astype(int)\n",
    "data['black_race'] = data.PTDTRACE.apply(lambda x: x == 2).astype(int)\n",
    "data['asian_race'] = data.PTDTRACE.apply(lambda x: x == 4).astype(int)\n",
    "data['mixed_race'] = data.PTDTRACE.apply(lambda x: x >= 6).astype(int)\n",
    "\n",
    "# Segment PENATVTY (country of birth)\n",
    "data['us_born'] = data.PENATVTY.apply(lambda x: x == 57).astype(int)\n",
    "data['us_territory_born'] = data.PENATVTY.apply(lambda x: x in [66, 73, 78, 96]).astype(int)\n",
    "data['born_outside_us'] = data.PENATVTY.apply(lambda x: x == 555).astype(int)\n",
    "\n",
    "# Segment PRINUSYR (immigrant entry year)\n",
    "data['imm_last_10'] = data.PRINUSYR.apply(lambda x: x >= 16).astype(int)\n",
    "data['imm_last_20'] = data.PRINUSYR.apply(lambda x: x >= 11 and x < 16).astype(int)\n",
    "data['imm_before_1988'] = data.PRINUSYR.apply(lambda x: x >= 1 and x < 11).astype(int)\n",
    "\n",
    "# Segment PUABSOT (did you have a job last week?)\n",
    "data['employed'] = data.PUABSOT.apply(lambda x: x == 1).astype(int)\n",
    "data['unemployed'] = data.PUABSOT.apply(lambda x: x == 2).astype(int) # This does not include retired; only unemployed\n",
    "\n",
    "# Segment PEIO1COW (employer type)\n",
    "data['fed_employed'] = data.PEIO1COW.apply(lambda x: x in [1, 2, 3]).astype(int)\n",
    "data['priv_employed'] = data.PEIO1COW.apply(lambda x: x in [4, 5]).astype(int)\n",
    "data['self_employed'] = data.PEIO1COW.apply(lambda x: x in [6, 7]).astype(int)\n",
    "\n",
    "# Segment PRCHLD (has own children)\n",
    "data['parent'] = data.PRCHLD.apply(lambda x: x >= 1).astype(int)\n",
    "\n",
    "# Segment PEAFWHN1 (military service period)\n",
    "data['ww2_vet'] = data.PEAFWHN1.apply(lambda x: x == 8).astype(int)\n",
    "data['vietnam_vet'] = data.PEAFWHN1.apply(lambda x: x == 4).astype(int)\n",
    "data['korea_vet'] = data.PEAFWHN1.apply(lambda x: x == 6).astype(int)\n",
    "\n",
    "# 0/1 PESEX (sex)\n",
    "data['male'] = data.PESEX.apply(lambda x: x == 1).astype(int)\n",
    "data['female'] = data.PESEX.apply(lambda x: x == 2).astype(int)\n",
    "\n",
    "# 0/1 PEHSPNON (hispanic?)\n",
    "data['hispanic'] = data.PEHSPNON.apply(lambda x: x == 1).astype(int)\n",
    "data['nonhispanic'] = data.PEHSPNON.apply(lambda x: x == 2).astype(int)\n",
    "\n",
    "# 0/1 PURETOT (retired?)\n",
    "data['retired'] = data.PURETOT.apply(lambda x: x == 1).astype(int)\n",
    "data['not_retired'] = data.PURETOT.apply(lambda x: x >= 2).astype(int) # 3 indicates they just retired; treat as not retired\n",
    "\n",
    "# 0/1 PEGRPROF (any grad/prof school courses for credit since bachelor's?)\n",
    "data['grad_courses_since_bach'] = data.PEGRPROF.apply(lambda x: x == 1).astype(int)\n",
    "data['no_grad_courses_since_bach'] = data.PEGRPROF.apply(lambda x: x == 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop allocation flag features; handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop allocation flag features\n",
    "allocation_flag_feats = [col for col in data.columns if col[:2] == 'PX']\n",
    "data.drop(allocation_flag_feats, axis=1, inplace=True)\n",
    "\n",
    "# Replace negative values (all forms of N/A) with NaN\n",
    "for feat in data.columns:\n",
    "    data[feat] = data[feat].apply(lambda x: np.NaN if x < 0 else x)\n",
    "    \n",
    "# Replace NaN with the mean of the column\n",
    "for feat in data.columns:\n",
    "    data[feat].fillna(data[feat].mean(), inplace=True)\n",
    "    \n",
    "# Check for columns that are all NaN, and delete them\n",
    "all_nan_cols = []\n",
    "for feat in data.columns:\n",
    "    if np.all(np.isnan(data[feat])):\n",
    "        all_nan_cols.append(feat)\n",
    "data.drop(all_nan_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PES1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PES1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-174ad48d5a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PES1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PES1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PES1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpes1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PES1'"
     ]
    }
   ],
   "source": [
    "pes1 = data['PES1']\n",
    "data.drop('PES1', axis=1, inplace=True)\n",
    "data['PES1'] = pes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'HRMONTH', 'HRYEAR4', 'HURESPLI', 'HUFINAL', 'HUSPNISH',\n",
       "       'HETENURE', 'HEHOUSUT', 'HETELHHD', 'HETELAVL',\n",
       "       ...\n",
       "       'vietnam_vet', 'korea_vet', 'male', 'female', 'hispanic', 'nonhispanic',\n",
       "       'retired', 'not_retired', 'grad_courses_since_bach',\n",
       "       'no_grad_courses_since_bach'],\n",
       "      dtype='object', length=329)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move PES1 (target feature) to the end of the dataframe\n",
    "pes1 = data['PES1']\n",
    "data.drop('PES1', axis=1, inplace=True)\n",
    "data['PES1'] = pes1\n",
    "\n",
    "# Make a dataframe of just the engineered features\n",
    "data_eng_feats_only = data[data.columns[-48:]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_eng_feats = [col for col in data.columns if col.isupper()]\n",
    "\n",
    "# Make a dataframe with no engineered features, just dropped allocation flags and NaNs removed\n",
    "data_orig_clean = data[['id'] + non_eng_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'HRMONTH', 'HRYEAR4', 'HURESPLI', 'HUFINAL', 'HUSPNISH',\n",
       "       'HETENURE', 'HEHOUSUT', 'HETELHHD', 'HETELAVL',\n",
       "       ...\n",
       "       'korea_vet', 'male', 'female', 'hispanic', 'nonhispanic', 'retired',\n",
       "       'not_retired', 'grad_courses_since_bach', 'no_grad_courses_since_bach',\n",
       "       'PES1'],\n",
       "      dtype='object', length=326)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that columns look right before writing out\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['low_fam_inc', 'med_fam_inc', 'high_fam_inc', 'one_person_hh',\n",
       "       'two_person_hh', 'multi_person_hh', 'farm_bus_hh', 'non_farm_bus_hh',\n",
       "       'northeast', 'midwest', 'south', 'west', 'too_young', 'youth',\n",
       "       'middle_age', 'elderly', 'hs_dropout', 'hs_grad', 'bachelor_deg',\n",
       "       'adv_deg', 'white_race', 'black_race', 'asian_race', 'mixed_race',\n",
       "       'us_born', 'us_territory_born', 'born_outside_us', 'imm_last_10',\n",
       "       'imm_last_20', 'imm_before_1988', 'employed', 'unemployed',\n",
       "       'fed_employed', 'priv_employed', 'self_employed', 'parent', 'ww2_vet',\n",
       "       'vietnam_vet', 'korea_vet', 'male', 'female', 'hispanic', 'nonhispanic',\n",
       "       'retired', 'not_retired', 'grad_courses_since_bach',\n",
       "       'no_grad_courses_since_bach', 'PES1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for the eng-feats-only dataframe\n",
    "data_eng_feats_only.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'HRMONTH', 'HRYEAR4', 'HURESPLI', 'HUFINAL', 'HUSPNISH',\n",
       "       'HETENURE', 'HEHOUSUT', 'HETELHHD', 'HETELAVL',\n",
       "       ...\n",
       "       'PEMOMTYP', 'PECOHAB', 'PEDISEAR', 'PEDISEYE', 'PEDISREM', 'PEDISPHY',\n",
       "       'PEDISDRS', 'PEDISOUT', 'PRDISFLG', 'PES1'],\n",
       "      dtype='object', length=279)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for the eng-feats-only dataframe\n",
    "data_orig_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out new data sets\n",
    "data_eng_feats_only.to_csv('train_2008_eng_feats_only.csv', index=False)\n",
    "data.to_csv('train_2008_with_eng_feats_no_allo_flags.csv', index=False)\n",
    "data_orig_clean.to_csv('train_2008_clean_no_eng_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove misleading features (mostly codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with data that has engineered features, negative values set to the mean of the feature, and allocation flags removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first list is from eyeballing; second is list of \"weight\" features that are just used for statistical tallying\n",
    "bad_cols = ['QSTNUM', 'GESTFIPS', 'GESTCEN', 'HRMIS', 'GTCBSA'] + [col for col in data.columns if col[-3:] == 'WGT']\n",
    "\n",
    "# drop 'em\n",
    "data.drop(bad_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### GTCBSASZ indicates size of city of residence - seems useful. Let's dummy it!\n",
    "\n",
    "# First we need to convert the codes into categorical variables\n",
    "city_size_map = {\n",
    "                    0:  'rural',\n",
    "                    2:  '100_250',\n",
    "                    3:  '250_500',\n",
    "                    4:  '500_1000',\n",
    "                    5:  '1000_2500',\n",
    "                    6:  '2500_5000',\n",
    "                    7:  '5000_plus'\n",
    "                }\n",
    "data['GTCBSASZ'] = data['GTCBSASZ'].map(city_size_map)\n",
    "\n",
    "# encode in dummy vars\n",
    "city_size_dummies = pd.get_dummies(data['GTCBSASZ'], prefix='city_size')\n",
    "\n",
    "# add these new features to the data\n",
    "data = pd.concat([data, city_size_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the original city size feature\n",
    "data.drop('GTCBSASZ', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'HRMONTH', 'HRYEAR4', 'HURESPLI', 'HUFINAL', 'HUSPNISH',\n",
       "       'HETENURE', 'HEHOUSUT', 'HETELHHD', 'HETELAVL',\n",
       "       ...\n",
       "       'not_retired', 'grad_courses_since_bach', 'no_grad_courses_since_bach',\n",
       "       'city_size_1000_2500', 'city_size_100_250', 'city_size_2500_5000',\n",
       "       'city_size_250_500', 'city_size_5000_plus', 'city_size_500_1000',\n",
       "       'city_size_rural'],\n",
       "      dtype='object', length=323)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep just the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_feats = pkl.load(open('keep_feats.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[keep_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data/test_cleaned_for_2012_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82820"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
